{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "583fb1b3-7fd3-480a-b016-8830767c5a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar 16 00:00:42 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce MX570           Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   48C    P0              8W /   30W |       7MiB /   2048MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2236      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbefa54d",
   "metadata": {},
   "source": [
    "## Check CUDA Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07e586a3-a068-46fc-a9bd-1c5e692f3e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.6.0+cu124\n",
      "CUDA Available: True\n",
      "CUDA Device Count: 1\n",
      "CUDA Device Name: NVIDIA GeForce MX570\n",
      "CUDA Compute Capability: (8, 6)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if PyTorch is installed\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "# Get the CUDA device count\n",
    "print(\"CUDA Device Count:\", torch.cuda.device_count())\n",
    "\n",
    "# Get the name of the CUDA device\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA Device Name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA Compute Capability:\", torch.cuda.get_device_capability(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd58ae5e",
   "metadata": {},
   "source": [
    "## Check the first frame for drawing lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df104727-68b6-430d-8a2f-4b6193c95f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"test_videos/Videos/1 (90).mp4\"  # Change this to your video file path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Define the video properties\n",
    "width = 1200  # Desired output width\n",
    "height = 700  # Desired output height\n",
    "dim = (width, height)\n",
    "\n",
    "# Read the first frame\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Check if the frame was successfully read\n",
    "if ret:\n",
    "    resized_frame = cv2.resize(frame, dim, interpolation=cv2.INTER_AREA)\n",
    "    cv2.imshow(\"First Frame\", resized_frame)\n",
    "    cv2.waitKey(0)  # Wait for a key press\n",
    "    cv2.destroyAllWindows()  # Close the window\n",
    "else:\n",
    "    print(\"Failed to read the first frame.\")\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae450cc",
   "metadata": {},
   "source": [
    "## Check model's categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e660478-13a8-4d32-a103-1073f36f71a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'motorcycle', 1: 'car', 2: 'bus', 3: 'light truck', 4: 'heavy truck'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "# Load the YOLO model\n",
    "model = YOLO('best1.pt')\n",
    "print(model.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "069969bd-0ac6-4eaf-9f84-894f114e9eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 42.3ms\n",
      "Speed: 2.2ms preprocess, 42.3ms inference, 92.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 32.0ms\n",
      "Speed: 1.8ms preprocess, 32.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 motorcycles, 1 car, 31.9ms\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 motorcycles, 1 car, 32.0ms\n",
      "Speed: 1.7ms preprocess, 32.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 motorcycles, 1 car, 31.9ms\n",
      "Speed: 1.3ms preprocess, 31.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 motorcycles, 1 car, 31.3ms\n",
      "Speed: 1.4ms preprocess, 31.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 motorcycles, 1 car, 31.2ms\n",
      "Speed: 1.4ms preprocess, 31.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 motorcycles, 1 car, 31.2ms\n",
      "Speed: 1.4ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 motorcycles, 1 car, 30.1ms\n",
      "Speed: 1.3ms preprocess, 30.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 motorcycles, 1 car, 30.1ms\n",
      "Speed: 1.4ms preprocess, 30.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 30.1ms\n",
      "Speed: 1.5ms preprocess, 30.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 28.5ms\n",
      "Speed: 1.4ms preprocess, 28.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 28.6ms\n",
      "Speed: 1.3ms preprocess, 28.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 28.6ms\n",
      "Speed: 2.7ms preprocess, 28.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 28.0ms\n",
      "Speed: 1.6ms preprocess, 28.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.9ms\n",
      "Speed: 2.3ms preprocess, 27.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.8ms\n",
      "Speed: 2.2ms preprocess, 27.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.5ms\n",
      "Speed: 1.4ms preprocess, 27.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.4ms\n",
      "Speed: 1.7ms preprocess, 27.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.4ms\n",
      "Speed: 1.8ms preprocess, 27.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.2ms\n",
      "Speed: 1.9ms preprocess, 27.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.4ms\n",
      "Speed: 2.4ms preprocess, 27.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.2ms\n",
      "Speed: 2.3ms preprocess, 27.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.1ms\n",
      "Speed: 1.4ms preprocess, 27.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.1ms\n",
      "Speed: 1.4ms preprocess, 27.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.1ms\n",
      "Speed: 1.6ms preprocess, 27.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.2ms\n",
      "Speed: 1.5ms preprocess, 27.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.4ms\n",
      "Speed: 1.8ms preprocess, 27.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.2ms\n",
      "Speed: 1.4ms preprocess, 27.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.1ms\n",
      "Speed: 1.4ms preprocess, 27.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.1ms\n",
      "Speed: 1.8ms preprocess, 27.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.8ms\n",
      "Speed: 2.6ms preprocess, 27.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.0ms\n",
      "Speed: 1.4ms preprocess, 27.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.1ms\n",
      "Speed: 2.0ms preprocess, 27.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.2ms\n",
      "Speed: 1.9ms preprocess, 27.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.2ms\n",
      "Speed: 1.9ms preprocess, 27.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.2ms\n",
      "Speed: 1.3ms preprocess, 27.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.2ms\n",
      "Speed: 1.5ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.2ms\n",
      "Speed: 1.9ms preprocess, 27.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.2ms\n",
      "Speed: 1.4ms preprocess, 27.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.2ms\n",
      "Speed: 1.4ms preprocess, 27.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.2ms\n",
      "Speed: 1.6ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.1ms\n",
      "Speed: 1.6ms preprocess, 27.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.2ms\n",
      "Speed: 1.8ms preprocess, 27.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.1ms\n",
      "Speed: 2.9ms preprocess, 27.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 car, 27.1ms\n",
      "Speed: 1.2ms preprocess, 27.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 2 cars, 27.0ms\n",
      "Speed: 1.2ms preprocess, 27.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 2 cars, 27.1ms\n",
      "Speed: 1.5ms preprocess, 27.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 27.2ms\n",
      "Speed: 2.2ms preprocess, 27.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 27.4ms\n",
      "Speed: 1.5ms preprocess, 27.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 2 cars, 27.3ms\n",
      "Speed: 1.4ms preprocess, 27.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 2 cars, 27.2ms\n",
      "Speed: 1.3ms preprocess, 27.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 2 cars, 27.3ms\n",
      "Speed: 1.9ms preprocess, 27.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 motorcycles, 2 cars, 27.4ms\n",
      "Speed: 2.7ms preprocess, 27.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 motorcycles, 2 cars, 27.1ms\n",
      "Speed: 1.3ms preprocess, 27.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 motorcycles, 2 cars, 27.1ms\n",
      "Speed: 1.4ms preprocess, 27.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 motorcycles, 1 car, 27.2ms\n",
      "Speed: 1.4ms preprocess, 27.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 motorcycles, 1 car, 27.3ms\n",
      "Speed: 2.6ms preprocess, 27.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 motorcycles, 1 car, 27.3ms\n",
      "Speed: 1.8ms preprocess, 27.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 motorcycles, 1 car, 27.2ms\n",
      "Speed: 1.3ms preprocess, 27.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO('best1.pt')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)  # Move model to GPU\n",
    "\n",
    "#class_list\n",
    "class_list = model.names \n",
    "\n",
    "### Open the video file\n",
    "cap = cv2.VideoCapture('test_videos/Videos/1 (91).mp4')\n",
    "\n",
    "# Dictionary to store object counts by class\n",
    "class_counts = defaultdict(int)\n",
    "class_counts_2 = defaultdict(int)\n",
    "class_counts_3 = defaultdict(int)\n",
    "class_counts_4 = defaultdict(int)\n",
    "\n",
    "# Dictionary to keep track of object IDs that have crossed the line\n",
    "crossed_ids = set()\n",
    "crossed_ids_2 = set()\n",
    "crossed_ids_3 = set()\n",
    "crossed_ids_4 = set()\n",
    "\n",
    "# Get the video properties\n",
    "width = 1200  # Desired output width\n",
    "height = 700  # Desired output height\n",
    "# fps = int(cap.get(cv2.CAP_PROP_FPS))  # Frames per second\n",
    "\n",
    "# #Define the codec and create VideoWriter object\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4 format\n",
    "# out = cv2.VideoWriter('output_video.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "\n",
    "###\n",
    "x1_start_line = 82\n",
    "y1_start_line = 601\n",
    "x1_end_line = 962\n",
    "y1_end_line = 325\n",
    "\n",
    "x2_start_line = 80\n",
    "y2_start_line = 244\n",
    "x2_end_line = 314\n",
    "y2_end_line = 188\n",
    "\n",
    "x3_start_line = 22\n",
    "y3_start_line = 294\n",
    "x3_end_line = 42\n",
    "y3_end_line = 424\n",
    "\n",
    "x4_start_line = 727\n",
    "y4_start_line = 196\n",
    "x4_end_line = 832\n",
    "y4_end_line = 216\n",
    "\n",
    "\n",
    "# Calculate 1st equation\n",
    "if x1_start_line:\n",
    "    A1 = np.array([[x1_start_line, 1],\n",
    "                [x1_end_line, 1]])\n",
    "\n",
    "    e1 = np.array([y1_start_line, y1_end_line])\n",
    "\n",
    "    a1, b1 = np.linalg.solve(A1, e1)\n",
    "\n",
    "# Calculate the 2nd equation\n",
    "if x2_start_line:\n",
    "    A2 = np.array([[x2_start_line, 1],\n",
    "                [x2_end_line, 1]])\n",
    "\n",
    "    e2 = np.array([y2_start_line, y2_end_line])\n",
    "\n",
    "    a2, b2 = np.linalg.solve(A2, e2)\n",
    "\n",
    "# Calculate the 3rd equation\n",
    "if x3_start_line:\n",
    "    A3 = np.array([[x3_start_line, 1],\n",
    "                [x3_end_line, 1]])\n",
    "\n",
    "    e3 = np.array([y3_start_line, y3_end_line])\n",
    "\n",
    "    a3, b3 = np.linalg.solve(A3, e3)\n",
    "\n",
    "# Calculate the 4th equation\n",
    "if x4_start_line:\n",
    "    A4 = np.array([[x4_start_line, 1],\n",
    "                [x4_end_line, 1]])\n",
    "\n",
    "    e4 = np.array([y4_start_line, y4_end_line])\n",
    "\n",
    "    a4, b4 = np.linalg.solve(A4, e4)\n",
    "\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    # Define new dimensions\n",
    "    dim = (width, height)\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    # Resize image\n",
    "    resized_frame = cv2.resize(frame, dim, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Run YOLO for tracking on the frame\n",
    "    results = model.track(resized_frame, persist=True)\n",
    "\n",
    "    # Ensure results are not empty\n",
    "    if results[0].boxes.data is not None:\n",
    "        # Get the detected boxes, their class indices, and track IDs\n",
    "        boxes = results[0].boxes.xyxy.cpu()\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "        class_indices = results[0].boxes.cls.int().cpu().tolist()\n",
    "        confidences = results[0].boxes.conf.cpu()\n",
    "\n",
    "        if x1_start_line:\n",
    "            cv2.line(resized_frame,  (x1_start_line, y1_start_line), (x1_end_line, y1_end_line), (0, 0, 255), 3)\n",
    "        if x2_start_line:\n",
    "            cv2.line(resized_frame,  (x2_start_line, y2_start_line), (x2_end_line, y2_end_line), (255, 0, 0), 3)\n",
    "        if x3_start_line:\n",
    "            cv2.line(resized_frame,  (x3_start_line, y3_start_line), (x3_end_line, y3_end_line), (0, 255, 255), 3)\n",
    "        if x4_start_line:\n",
    "            cv2.line(resized_frame,  (x4_start_line, y4_start_line), (x4_end_line, y4_end_line), (0, 255, 0), 3)\n",
    "        #cv2.putText(resized_frame, 'Red Line', (690, line_y_red - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        \n",
    "\n",
    "        # Loop through each detected object\n",
    "        for box, track_id, class_idx, conf in zip(boxes, track_ids, class_indices, confidences):\n",
    "            x1, y1, x2, y2 = map(int, box)    #(x1,y1): top left >< bottom right\n",
    "            cx = (x1 + x2) // 2    #Center point\n",
    "            cy = (y1 + y2) // 2\n",
    "\n",
    "            class_name = class_list[class_idx]\n",
    "\n",
    "            cv2.circle(resized_frame, (cx, cy), 4, (0, 0 , 255), -1)\n",
    "        \n",
    "            cv2.putText(resized_frame, f\"ID: {track_id} {class_name}\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)    #font - size - color - thickness\n",
    "        \n",
    "            cv2.rectangle(resized_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)    #frame - topleft - bottomright - color - thickness\n",
    "\n",
    "            # Check if the object has crossed the lines\n",
    "            if x1_start_line:\n",
    "                if cy <= (a1*cx + b1 + 30) and cy >= (a1*cx + b1 - 30) and cx >= x1_start_line and cx <= x1_end_line and track_id not in crossed_ids:\n",
    "                    # Mark the object as crossed\n",
    "                    crossed_ids.add(track_id)\n",
    "                    class_counts[class_name] += 1\n",
    "\n",
    "            if x2_start_line:\n",
    "                if cy <= (a2*cx + b2 + 30) and cy >= (a2*cx + b2 - 30) and cx >= x2_start_line and cx <= x2_end_line and track_id not in crossed_ids_2:\n",
    "                    # Mark the object as crossed\n",
    "                    crossed_ids_2.add(track_id)\n",
    "                    class_counts_2[class_name] += 1\n",
    "\n",
    "            if x3_start_line:\n",
    "                if cy <= (a3*cx + b3 + 30) and cy >= (a3*cx + b3 - 30) and cx >= x3_start_line and cx <= x3_end_line and track_id not in crossed_ids_3:\n",
    "                    # Mark the object as crossed\n",
    "                    crossed_ids_3.add(track_id)\n",
    "                    class_counts_3[class_name] += 1\n",
    "\n",
    "            if x4_start_line:\n",
    "                if cy <= (a4*cx + b4 + 30) and cy >= (a4*cx + b4 - 30) and cx >= x4_start_line and cx <= x4_end_line and track_id not in crossed_ids_4:\n",
    "                    # Mark the object as crossed\n",
    "                    crossed_ids_4.add(track_id)\n",
    "                    class_counts_4[class_name] += 1\n",
    "    \n",
    "        # Display the counts on the frame\n",
    "            x1_offset = 50\n",
    "            y1_offset = 60\n",
    "            if x1_start_line:\n",
    "                cv2.putText(resized_frame, \"Road ID: 01\", (x1_offset, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "            for class_name, count in class_counts.items():\n",
    "                cv2.putText(resized_frame, f\"{class_name}: {count}\", (x1_offset, y1_offset),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "                y1_offset += 30\n",
    "\n",
    "            x2_offset = 1000\n",
    "            y2_offset = 60\n",
    "            if x2_start_line:\n",
    "                cv2.putText(resized_frame, \"Road ID: 02\", (x2_offset, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
    "            for class_name, count in class_counts_2.items():\n",
    "                cv2.putText(resized_frame, f\"{class_name}: {count}\", (x2_offset, y2_offset),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
    "                y2_offset += 30\n",
    "\n",
    "            x3_offset = 50\n",
    "            y3_offset = 500\n",
    "            if x3_start_line:\n",
    "                cv2.putText(resized_frame, \"Road ID: 03\", (x3_offset, 470),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "            for class_name, count in class_counts_3.items():\n",
    "                cv2.putText(resized_frame, f\"{class_name}: {count}\", (x3_offset, y3_offset),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "                y3_offset += 30\n",
    "\n",
    "            x4_offset = 1000\n",
    "            y4_offset = 500\n",
    "            if x4_start_line:\n",
    "                cv2.putText(resized_frame, \"Road ID: 04\", (x4_offset, 470),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "            for class_name, count in class_counts_4.items():\n",
    "                cv2.putText(resized_frame, f\"{class_name}: {count}\", (x4_offset, y4_offset),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "                y4_offset += 30\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Show the frame\n",
    "    cv2.imshow('YOLO Object Tracking & Counting', resized_frame)\n",
    "\n",
    "    # Exit loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d509213f-7e71-4abf-aaa6-653afd7e31a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {})\n",
      "defaultdict(<class 'int'>, {'motorcycle': 1})\n",
      "defaultdict(<class 'int'>, {})\n",
      "defaultdict(<class 'int'>, {})\n"
     ]
    }
   ],
   "source": [
    "print(class_counts)\n",
    "print(class_counts_2)\n",
    "print(class_counts_3)\n",
    "print(class_counts_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b531ba-a169-49f2-928e-fd34773ddf29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
